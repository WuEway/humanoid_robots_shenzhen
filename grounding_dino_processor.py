"""
GroundingDinoå¤„ç†å™¨çš„è¯¦ç»†å®ç°
åŒ…å«ç›®æ ‡æ£€æµ‹å’Œç‚¹äº‘æå–åŠŸèƒ½
é›†æˆçœŸå®çš„GroundingDino+SAMæ¨¡å‹
"""

import numpy as np
import cv2
import pyrealsense2 as rs
from typing import Dict, List, Tuple, Optional, Any
import sys
import os

from realsense_system import RGBDProcessor, RGBDData




class AdvancedGroundingDinoProcessor(RGBDProcessor):
    """é«˜çº§GroundingDinoå¤„ç†å™¨ - é›†æˆçœŸå®çš„GroundingDino+SAMæ¨¡å‹"""
    
    def __init__(self, 
                 grounding_dino_config_path: str = "/home/yiwei/code_from_web/cv_algorithms/Grounded-Segment-Anything/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py",
                 grounding_dino_checkpoint_path: str = "/home/yiwei/data_repo/Grounded-SAM/groundingdino_swint_ogc.pth",
                 sam_encoder_version: str = "vit_h",
                 sam_checkpoint_path: str = "/home/yiwei/data_repo/Grounded-SAM/sam_vit_h_4b8939.pth",
                 box_threshold: float = 0.35,
                 text_threshold: float = 0.25,
                 nms_threshold: float = 0.5,
                 device: str = "cuda"):
        
        self.box_threshold = box_threshold
        self.text_threshold = text_threshold
        self.nms_threshold = nms_threshold
        
        # åˆå§‹åŒ–torchè®¾å¤‡
        import torch
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # ç‚¹äº‘è½¬æ¢å™¨
        self.pc = rs.pointcloud()
        self.points = rs.points()
        
        # æ¨¡å‹è·¯å¾„
        self.grounding_dino_config_path = grounding_dino_config_path
        self.grounding_dino_checkpoint_path = grounding_dino_checkpoint_path
        self.sam_encoder_version = sam_encoder_version
        self.sam_checkpoint_path = sam_checkpoint_path
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.grounding_dino_model = None
        self.sam_predictor = None
        
        # ICPé…å‡†ç›¸å…³å±æ€§ - æŒ‰ç‰©ä½“ç±»åˆ«åˆ†åˆ«ç»´æŠ¤
        self.accumulated_pcds = {}   # æ¯ä¸ªç‰©ä½“ç±»åˆ«ç»´æŠ¤ç‹¬ç«‹çš„ç´¯ç§¯ç‚¹äº‘ {label: pointcloud}
        self.frame_count = 0         # å¸§è®¡æ•°å™¨
        
        # å»¶è¿ŸåŠ è½½æ¨¡å‹
        self._load_models()
        
        print(f"GroundingDinoå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        
    def _load_models(self):
        """åŠ è½½GroundingDinoå’ŒSAMæ¨¡å‹"""
        # å¯¼å…¥æ·±åº¦å­¦ä¹ åº“
        from groundingdino.util.inference import Model
        from segment_anything import sam_model_registry, SamPredictor
        
        # åŠ è½½GroundingDinoæ¨¡å‹
        print("æ­£åœ¨åŠ è½½GroundingDinoæ¨¡å‹...")
        self.grounding_dino_model = Model(
            model_config_path=self.grounding_dino_config_path,
            model_checkpoint_path=self.grounding_dino_checkpoint_path
        )
        print("GroundingDinoæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½SAMæ¨¡å‹
        print("æ­£åœ¨åŠ è½½SAMæ¨¡å‹...")
        sam = sam_model_registry[self.sam_encoder_version](checkpoint=self.sam_checkpoint_path)
        sam.to(device=self.device)
        self.sam_predictor = SamPredictor(sam)
        print("SAMæ¨¡å‹åŠ è½½æˆåŠŸ")
        
    def process(self, data: RGBDData, text_prompt: str = "object") -> Dict[str, Any]:
        """
        å¤„ç†RGBDæ•°æ®ï¼Œæ£€æµ‹ç›®æ ‡å¹¶æå–ç‚¹äº‘
        
        Args:
            data: RGBDæ•°æ®
            text_prompt: æ£€æµ‹ç›®æ ‡çš„æ–‡æœ¬æè¿°
            
        Returns:
            åŒ…å«æ£€æµ‹ç»“æœå’Œç‚¹äº‘çš„å­—å…¸
        """
        if not data.is_valid():
            return {"success": False, "error": "Invalid RGBD data"}
            
        try:
            # æ›´æ–°å¸§è®¡æ•°å™¨
            self.frame_count += 1
            # 1. ç›®æ ‡æ£€æµ‹
            detections = self._detect_objects(data.color_image, text_prompt)
            
            # 2. ä¸ºæ¯ä¸ªæ£€æµ‹ç»“æœæå–ç‚¹äº‘
            point_clouds = []
            for detection in detections:
                point_cloud_data = self._extract_point_cloud(data, detection)
                if point_cloud_data is not None:
                    point_clouds.append({
                        "detection": detection,
                        "point_cloud": point_cloud_data
                    })
            
            # 3. å¯è§†åŒ–ç»“æœ
            result_image = self._visualize_detections(data.color_image, detections)
            
            return {
                "success": True,
                "detections": detections,
                "point_clouds": point_clouds,
                "result_image": result_image
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _detect_objects(self, image: np.ndarray, text_prompt: str) -> List[Dict]:
        """
        ä½¿ç”¨GroundingDinoæ£€æµ‹ç›®æ ‡ç‰©ä½“
        
        Args:
            image: è¾“å…¥RGBå›¾åƒ (BGRæ ¼å¼ï¼ŒOpenCVæ ‡å‡†)
            text_prompt: ç›®æ ‡æè¿°æ–‡æœ¬
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦ã€æ ‡ç­¾å’Œæ©ç 
        """
        detections = []
        
        try:
            # æ ¼å¼åŒ–æ–‡æœ¬æç¤ºï¼ˆæ”¯æŒå¤šä¸ªç±»åˆ«ï¼‰ï¼Œå°†"."åˆ†éš”çš„ç±»åˆ«è½¬æ¢ä¸ºåˆ—è¡¨
            if isinstance(text_prompt, str):
                classes = [c.strip() for c in text_prompt.split(".") if c.strip()]
            else:
                classes = text_prompt
            
            # GroundingDinoæ£€æµ‹ï¼ˆéœ€è¦RGBæ ¼å¼ï¼‰
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ä½¿ç”¨GroundingDinoè¿›è¡Œç›®æ ‡æ£€æµ‹
            print("ğŸ¤– ä½¿ç”¨çœŸå®GroundingDinoæ¨¡å‹æ£€æµ‹")
            detections_sv = self.grounding_dino_model.predict_with_classes(
                image=rgb_image,
                classes=classes,
                box_threshold=self.box_threshold,
                text_threshold=self.text_threshold
            )
            
            print(f"GroundingDinoæ£€æµ‹åˆ° {len(detections_sv.xyxy)} ä¸ªç›®æ ‡")
            
            if len(detections_sv.xyxy) == 0:
                return []
            
            # NMSåå¤„ç†
            import torch
            import torchvision
            nms_idx = torchvision.ops.nms(
                torch.from_numpy(detections_sv.xyxy),
                torch.from_numpy(detections_sv.confidence),
                self.nms_threshold
            ).numpy().tolist()
            
            # è¿‡æ»¤æ£€æµ‹ç»“æœ
            filtered_boxes = detections_sv.xyxy[nms_idx]
            filtered_confidences = detections_sv.confidence[nms_idx]
            filtered_class_ids = detections_sv.class_id[nms_idx]
            
            print(f"NMSåä¿ç•™ {len(filtered_boxes)} ä¸ªç›®æ ‡")
            
            # ä½¿ç”¨SAMç”Ÿæˆç²¾ç¡®æ©ç 
            masks = self._segment_with_sam(rgb_image, filtered_boxes)
            
            # æ ¼å¼åŒ–æ£€æµ‹ç»“æœ
            all_detections = []
            for i, (box, confidence, class_id, mask) in enumerate(
                zip(filtered_boxes, filtered_confidences, filtered_class_ids, masks)
            ):
                x1, y1, x2, y2 = box.astype(int)
                all_detections.append({
                    "bbox": [x1, y1, x2 - x1, y2 - y1],  # [x, y, width, height]
                    "xyxy": [x1, y1, x2, y2],  # [x1, y1, x2, y2]
                    "confidence": float(confidence),
                    "class_id": int(class_id),
                    "label": classes[class_id] if class_id < len(classes) else "object",
                    "mask": mask
                })
            
            # æ¯ä¸ªç±»åˆ«åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ
            detections = self._pick_best_detection_per_class(all_detections)
            
            return detections
            
        except Exception as e:
            print(f"æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
            return []
    
    def _pick_best_detection_per_class(self, detections: List[Dict]) -> List[Dict]:
        """æ¯ä¸ªç±»åˆ«åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ"""
        if not detections:
            return detections
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        class_groups = {}
        for detection in detections:
            class_id = detection["class_id"]
            if class_id not in class_groups:
                class_groups[class_id] = []
            class_groups[class_id].append(detection)
        
        # æ¯ä¸ªç±»åˆ«ä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ª
        filtered_detections = []
        for class_id, group in class_groups.items():
            # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå–æœ€é«˜çš„
            best_detection = max(group, key=lambda x: x["confidence"])
            filtered_detections.append(best_detection)
            
            print(f"ğŸ“¦ ç±»åˆ« '{best_detection['label']}': ä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ ({best_detection['confidence']:.3f})")
        
        return filtered_detections

    def _segment_with_sam(self, image: np.ndarray, boxes: np.ndarray) -> List[np.ndarray]:
        """ä½¿ç”¨SAMå¯¹æ£€æµ‹æ¡†è¿›è¡Œç²¾ç¡®åˆ†å‰²ï¼ˆæ¥è‡ªSAMçš„ä¾‹ç¨‹ï¼‰"""
        self.sam_predictor.set_image(image)
        result_masks = []
        
        for box in boxes:
            masks, scores, logits = self.sam_predictor.predict(
                box=box,
                multimask_output=True
            )
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ©ç 
            index = np.argmax(scores)
            result_masks.append(masks[index])
            
        return result_masks
    

    
    def _extract_point_cloud(self, data: RGBDData, detection: Dict) -> Optional[Dict]:
        """
        æ ¹æ®æ£€æµ‹ç»“æœæå–ç›®æ ‡ç‰©ä½“çš„ç‚¹äº‘ï¼ˆåŒ…å«é¢œè‰²ä¿¡æ¯ï¼‰
        
        Args:
            data: RGBDæ•°æ®
            detection: æ£€æµ‹ç»“æœ
            
        Returns:
            åŒ…å«ç‚¹äº‘å’Œé¢œè‰²ä¿¡æ¯çš„å­—å…¸ {"points": (N, 3), "colors": (N, 3)} æˆ– None
        """
        try:
            if data.depth_frame is None:
                return None
                
            # å¿…é¡»ä½¿ç”¨SAMç”Ÿæˆçš„maskï¼Œç¡®ä¿ç²¾ç¡®åˆ†å‰²
            mask = detection.get("mask")
            if mask is None:
                print("âš ï¸  è­¦å‘Š: æ£€æµ‹ç»“æœä¸­æ²¡æœ‰maskï¼Œè·³è¿‡ç‚¹äº‘æå–")
                return None
            
            # ç”Ÿæˆç‚¹äº‘
            self.pc.map_to(data.color_frame)
            self.points = self.pc.calculate(data.depth_frame)
            
            # è·å–é¡¶ç‚¹åæ ‡å’Œé¢œè‰²
            vertices = np.asanyarray(self.points.get_vertices()).view(np.float32).reshape(-1, 3)
            tex_coords = np.asanyarray(self.points.get_texture_coordinates()).view(np.float32).reshape(-1, 2)
            
            # è·å–RGBå›¾åƒæ•°æ®
            color_image = np.asanyarray(data.color_frame.get_data())
            h, w = color_image.shape[:2]
            
            # åº”ç”¨æ©ç è¿‡æ»¤ç‚¹äº‘
            mask_flat = mask.flatten()
            valid_indices = np.where(mask_flat > 0)[0]
            
            if len(valid_indices) == 0:
                return None
                
            # æå–ç›®æ ‡ç‚¹äº‘å’Œå¯¹åº”çš„çº¹ç†åæ ‡
            target_points = vertices[valid_indices]
            target_tex_coords = tex_coords[valid_indices]
            
            # è¿‡æ»¤æ— æ•ˆç‚¹ï¼ˆz=0çš„ç‚¹ï¼‰
            valid_mask = target_points[:, 2] > 0
            valid_points = target_points[valid_mask]
            valid_tex_coords = target_tex_coords[valid_mask]
            
            if len(valid_points) == 0:
                return None
            
            # ä»RGBå›¾åƒä¸­æå–å¯¹åº”çš„é¢œè‰²
            colors = []
            for tex_coord in valid_tex_coords:
                # çº¹ç†åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
                x = int(tex_coord[0] * w)
                y = int(tex_coord[1] * h)
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x = max(0, min(x, w-1))
                y = max(0, min(y, h-1))
                
                # è·å–RGBé¢œè‰² (æ³¨æ„OpenCVæ˜¯BGRæ ¼å¼)
                b, g, r = color_image[y, x]
                colors.append([r, g, b])  # è½¬æ¢ä¸ºRGBæ ¼å¼
            
            colors = np.array(colors, dtype=np.uint8)
            
            return {
                "points": valid_points,
                "colors": colors
            }
            
        except Exception as e:
            print(f"ç‚¹äº‘æå–å¤±è´¥: {e}")
            return None
    
    def _visualize_detections(self, image: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        result_image = image.copy()
        
        for i, detection in enumerate(detections):
            bbox = detection["bbox"]
            confidence = detection["confidence"]
            label = detection["label"]
            
            x, y, w, h = bbox
            
            # ä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ä¸åŒç›®æ ‡
            colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
            color = colors[i % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(result_image, (x, y), (x + w, y + h), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾å’Œç½®ä¿¡åº¦
            text = f"{label}: {confidence:.2f}"
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(result_image, (x, y + text_size[1]), 
                         (x + text_size[0], y), color, -1)
            cv2.putText(result_image, text, (x, y + text_size[1]), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # ç»˜åˆ¶æ©ç ï¼ˆåŠé€æ˜ï¼‰
            if "mask" in detection and detection["mask"] is not None:
                mask = detection["mask"]
                if mask.dtype == bool:
                    mask = mask.astype(np.uint8) * 255
                    
                # åˆ›å»ºå½©è‰²æ©ç 
                colored_mask = np.zeros_like(result_image)
                colored_mask[mask > 0] = color
                result_image = cv2.addWeighted(result_image, 0.7, colored_mask, 0.3, 0)
        
        return result_image
    

    



class InteractiveGroundingDinoVisualizer(RGBDProcessor):
    """äº¤äº’å¼GroundingDinoå¯è§†åŒ–å™¨"""
    
    def __init__(self, window_name: str = "GroundingDino Results"):
        self.window_name = window_name
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.processor = AdvancedGroundingDinoProcessor()
        print("ğŸ¤– ä½¿ç”¨GroundingDino+SAMæ¨¡å‹")
            
        self.current_prompt = "delivery box. pink takeout bag"  # é»˜è®¤æ£€æµ‹å¤–å–è¢‹
        self.frame_count = 0
        self.last_process_frame = 0
        self.last_results = None  # ç¼“å­˜æœ€è¿‘ä¸€æ¬¡çš„æ£€æµ‹ç»“æœ
        
        # ICPé…å‡†ç›¸å…³ - æŒ‰ç‰©ä½“ç±»åˆ«åˆ†åˆ«ç»´æŠ¤
        self.accumulated_pcds = {}  # æ¯ä¸ªç‰©ä½“ç±»åˆ«ç»´æŠ¤ç‹¬ç«‹çš„ç´¯ç§¯ç‚¹äº‘ {label: pointcloud}
        self.enable_icp = True  # æ˜¯å¦å¯ç”¨ICPé…å‡†
        
    def process(self, data: RGBDData) -> bool:
        """å¤„ç†å¹¶æ˜¾ç¤ºæ£€æµ‹ç»“æœ"""
        if not data.is_valid():
            return True
            
        self.frame_count += 1
        
        # æ¯30å¸§å¤„ç†ä¸€æ¬¡ï¼ˆé™ä½è®¡ç®—é¢‘ç‡ï¼ŒçœŸå®æ¨¡å‹è®¡ç®—è¾ƒæ…¢ï¼‰
        if self.frame_count - self.last_process_frame >= 30:
            self.last_process_frame = self.frame_count
            print(f"\n=== ç¬¬ {self.frame_count} å¸§ - æ£€æµ‹ç›®æ ‡: '{self.current_prompt}' ===")
            
            # æ‰§è¡Œæ£€æµ‹
            self.last_results = self.processor.process(data, self.current_prompt)
            
            if self.last_results["success"]:
                # æ˜¾ç¤ºç»“æœ
                result_image = self.last_results["result_image"]
                cv2.imshow(self.window_name, result_image)
                
                # è‡ªåŠ¨ä¿å­˜æ£€æµ‹ç»“æœ
                self._save_detection_results(data, self.last_results)
                
                # æ‰“å°æ£€æµ‹ä¿¡æ¯
                detections = self.last_results["detections"]
                if detections:
                    print(f"âœ… æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡:")
                    for i, det in enumerate(detections):
                        print(f"  {i+1}. {det['label']}: {det['confidence']:.3f}")
                        
                        # å¦‚æœæœ‰ç‚¹äº‘ï¼Œæ‰“å°ç‚¹äº‘ä¿¡æ¯
                        point_clouds = self.last_results["point_clouds"]
                        if i < len(point_clouds) and point_clouds[i]["point_cloud"] is not None:
                            pc_size = len(point_clouds[i]["point_cloud"]["points"])
                            print(f" ç‚¹äº‘å¤§å°: {pc_size} ä¸ªç‚¹")
                else:
                    print(f"âŒ æœªæ£€æµ‹åˆ°ç›®æ ‡: '{self.current_prompt}'")
            else:
                # æ˜¾ç¤ºåŸå›¾
                cv2.imshow(self.window_name, data.color_image)
                print(f"âŒ æ£€æµ‹å¤±è´¥: {self.last_results.get('error', 'Unknown error')}")
                self.last_results = None
        # else:
        #     # æ˜¾ç¤ºåŸå›¾æˆ–ä¸Šä¸€æ¬¡çš„ç»“æœ
        #     cv2.imshow(self.window_name, data.color_image)

        
        # å¤„ç†é”®ç›˜è¾“å…¥
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or key == 27:  # qæˆ–ESCé€€å‡º
            return False
        elif key == ord('1'):  # 1æ£€æµ‹å¤–å–è¢‹
            self.current_prompt = "delivery box. pink takeout bag"
            print(f"\nğŸ”„ åˆ‡æ¢æ£€æµ‹ç›®æ ‡: {self.current_prompt}")
        elif key == ord('2'):  # 2æ£€æµ‹åŒ…
            self.current_prompt = "bag"
            print(f"\nğŸ”„ åˆ‡æ¢æ£€æµ‹ç›®æ ‡: {self.current_prompt}")
        elif key == ord('3'):  # 3æ£€æµ‹ç›’å­
            self.current_prompt = "box"
            print(f"\nğŸ”„ åˆ‡æ¢æ£€æµ‹ç›®æ ‡: {self.current_prompt}")
        elif key == ord('i'):  # iå¼€å¯/å…³é—­ICPé…å‡†
            self.enable_icp = not self.enable_icp
            status = "å¼€å¯" if self.enable_icp else "å…³é—­"
            print(f"\nğŸ”„ ICPé…å‡†åŠŸèƒ½å·²{status}")
            if not self.enable_icp:
                print("ğŸ’¡ ç¦ç”¨ICPååªä¿å­˜åŸå§‹ç‚¹äº‘")
            
        return True

    
    def _save_detection_results(self, data: RGBDData, results: Dict):
        """ä¿å­˜æ£€æµ‹ç»“æœï¼šç‚¹äº‘ï¼ˆæ— é¢œè‰²+æœ‰é¢œè‰²ï¼‰å’Œå¯è§†åŒ–å›¾åƒ"""
        try:
            import os
            
            # åˆ›å»ºç»“æœç›®å½•
            results_dir = "detection_results"
            os.makedirs(results_dir, exist_ok=True)
            
            # ä¸ºå½“å‰å¸§åˆ›å»ºå­ç›®å½•
            frame_name = f"frame_{self.frame_count:04d}_{self.current_prompt.replace(' ', '_')}"
            frame_dir = os.path.join(results_dir, frame_name)
            os.makedirs(frame_dir, exist_ok=True)
            
            detections = results["detections"]
            point_clouds = results["point_clouds"]
            
            # 1. ä¿å­˜RGBå›¾åƒå åŠ SAMåˆ†å‰²ç»“æœå’ŒDINOæ£€æµ‹æ¡†
            result_path = os.path.join(frame_dir, "detection_overlay.jpg")
            cv2.imwrite(result_path, results["result_image"])
            
            # 1.1. é¢å¤–ä¿å­˜jpgåˆ°ä¸“é—¨çš„å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œæ–¹ä¾¿æŸ¥çœ‹
            # åˆ›å»ºå›¾ç‰‡åº“ç›®å½•
            gallery_dir = "detection_results/image_gallery"
            os.makedirs(gallery_dir, exist_ok=True)
            cv2.imwrite(os.path.join(gallery_dir, f"{frame_name}.jpg"), results["result_image"])

            # 2. ä¸ºæ¯ä¸ªæ£€æµ‹ç›®æ ‡ä¿å­˜ç‚¹äº‘å’Œæ‰§è¡ŒICPé…å‡†
            for i, detection in enumerate(detections):
                obj_name = f"{detection['label'].replace(' ', '_')}_{i:02d}"
                
                # ä¿å­˜å¯¹åº”çš„ç‚¹äº‘
                if i < len(point_clouds) and point_clouds[i]["point_cloud"] is not None:
                    pc_data = point_clouds[i]["point_cloud"]
                    
                    # ä¿å­˜åŸå§‹ç‚¹äº‘ï¼ˆæœ‰é¢œè‰²çš„ï¼‰
                    pc_path = os.path.join(frame_dir, f"{obj_name}_pointcloud.ply")
                    self.save_point_cloud(pc_data, pc_path)
                    
                    # æ‰§è¡ŒICPé…å‡†å¹¶æ›´æ–°å…¨å±€é…å‡†æ–‡ä»¶ï¼ˆæŒ‰ç‰©ä½“ç±»åˆ«åˆ†åˆ«ç»´æŠ¤ï¼‰
                    if self.enable_icp:
                        obj_label = detection['label']  # è·å–ç‰©ä½“ç±»åˆ«æ ‡ç­¾
                        self._perform_incremental_icp_by_class(pc_data, obj_label, obj_name)
            
            print(f"ğŸ’¾ å·²ä¿å­˜æ£€æµ‹ç»“æœåˆ°: {frame_dir}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ£€æµ‹ç»“æœå¤±è´¥: {e}")

    def save_point_cloud(self, point_cloud_data, filepath: str) -> bool:
        """ä¿å­˜ç‚¹äº‘åˆ°æ–‡ä»¶ï¼ˆæ‰€æœ‰ç‚¹äº‘éƒ½åŒ…å«é¢œè‰²ä¿¡æ¯ï¼‰"""
        try:
            points = point_cloud_data["points"]
            colors = point_cloud_data["colors"]
            
            # ä¿å­˜å¸¦é¢œè‰²çš„PLYæ–‡ä»¶
            base_name = filepath.rsplit('.', 1)[0]
            rgb_filepath = f"{base_name}_rgb.ply"
            self._save_colored_ply(points, colors, rgb_filepath)
            print(f"å½©è‰²ç‚¹äº‘å·²ä¿å­˜åˆ°: {rgb_filepath}")
            
            return True
            
        except Exception as e:
            print(f"ä¿å­˜ç‚¹äº‘å¤±è´¥: {e}")
            return False
    
    def _save_colored_ply(self, points: np.ndarray, colors: np.ndarray, filepath: str):
        """ä¿å­˜å¸¦é¢œè‰²çš„ç‚¹äº‘ä¸ºPLYæ ¼å¼"""
        with open(filepath, 'w') as f:
            f.write("ply\n")
            f.write("format ascii 1.0\n")
            f.write(f"element vertex {len(points)}\n")
            f.write("property float x\n")
            f.write("property float y\n")
            f.write("property float z\n")
            f.write("property uchar red\n")
            f.write("property uchar green\n")
            f.write("property uchar blue\n")
            f.write("end_header\n")
            
            for point, color in zip(points, colors):
                f.write(f"{point[0]} {point[1]} {point[2]} {color[0]} {color[1]} {color[2]}\n")

    def _perform_incremental_icp_by_class(self, pc_data, obj_label: str, obj_name: str):
        """
        æ‰§è¡ŒæŒ‰ç‰©ä½“ç±»åˆ«åˆ†ç»„çš„å¢é‡å¼ICPé…å‡†
        æ¯ä¸ªç‰©ä½“ç±»åˆ«ç»´æŠ¤ç‹¬ç«‹çš„ç´¯ç§¯ç‚¹äº‘å’Œé…å‡†å†å²
        
        Args:
            pc_data: ç‚¹äº‘æ•°æ®
            obj_label: ç‰©ä½“ç±»åˆ«æ ‡ç­¾ (å¦‚ "delivery_box", "pink_takeout_bag")
            obj_name: å…·ä½“å®ä¾‹åç§° (å¦‚ "delivery_box_00")
        """
        try:
            import open3d as o3d
            import numpy as np
            import os
            
            # æ ‡å‡†åŒ–æ ‡ç­¾åç§°ï¼ˆå»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
            clean_label = obj_label.replace(' ', '_').replace('.', '_').lower()
            
            # ä¸ºæ¯ä¸ªç‰©ä½“ç±»åˆ«åˆ›å»ºç‹¬ç«‹çš„å…¨å±€é…å‡†æ–‡ä»¶è·¯å¾„
            global_registered_path = f"detection_results/global_registered_{clean_label}.ply"
            
            # ä»ç‚¹äº‘æ•°æ®ä¸­æå–ç‚¹åæ ‡å’Œé¢œè‰²
            points = pc_data["points"]
            colors = pc_data["colors"]
            
            # åˆ›å»ºå½“å‰å¸§ç‚¹äº‘å¯¹è±¡ï¼ˆç›®æ ‡ç‚¹äº‘ï¼‰
            current_pcd = o3d.geometry.PointCloud()
            current_pcd.points = o3d.utility.Vector3dVector(points)
            colors_normalized = colors.astype(np.float64) / 255.0
            current_pcd.colors = o3d.utility.Vector3dVector(colors_normalized)
            
            # æ£€æŸ¥ç‚¹äº‘è´¨é‡
            if len(current_pcd.points) < 10:
                print(f"âš ï¸ {obj_label} ç‚¹äº‘ç‚¹æ•°å¤ªå°‘({len(current_pcd.points)})ï¼Œè·³è¿‡ICPé…å‡†")
                return
            
            # å¦‚æœè¿™æ˜¯è¯¥ç±»åˆ«çš„ç¬¬ä¸€å¸§ï¼Œç›´æ¥ä¿å­˜ä¸ºè¯¥ç±»åˆ«çš„ç´¯ç§¯å†å²ç‚¹äº‘
            if clean_label not in self.accumulated_pcds:
                self.accumulated_pcds[clean_label] = current_pcd
                o3d.io.write_point_cloud(global_registered_path, current_pcd)
                print(f"ğŸ”„ {obj_label} é¦–å¸§ç‚¹äº‘å·²ä¿å­˜: {obj_name} (ç‚¹æ•°: {len(current_pcd.points)})")
                return
            
            # è·å–è¯¥ç±»åˆ«çš„å†å²ç´¯ç§¯ç‚¹äº‘
            class_accumulated_pcd = self.accumulated_pcds[clean_label]
            
            print(f"ğŸ”„ {obj_label} ICPé…å‡†: å†å²ç‚¹äº‘({len(class_accumulated_pcd.points)}ç‚¹) -> å½“å‰å¸§({len(current_pcd.points)}ç‚¹)")
            
            # é¢„å¤„ç†ï¼šä¼°è®¡æ³•å‘é‡
            current_pcd.estimate_normals()
            class_accumulated_pcd.estimate_normals()
            
            # ICPé…å‡†å‚æ•°
            threshold = 0.02  # å¯¹åº”ç‚¹è·ç¦»é˜ˆå€¼(ç±³)
            
            try:
                # å…ˆå°è¯•Colored ICPï¼ˆä¿æŒé¢œè‰²ä¸€è‡´æ€§ï¼‰
                reg_p2p = o3d.pipelines.registration.registration_colored_icp(
                    source=class_accumulated_pcd,     # æºç‚¹äº‘ï¼šè¯¥ç±»åˆ«çš„å†å²ç´¯ç§¯ç‚¹äº‘
                    target=current_pcd,               # ç›®æ ‡ç‚¹äº‘ï¼šå½“å‰å¸§ç‚¹äº‘
                    max_correspondence_distance=threshold,
                    init=np.eye(4),
                    estimation_method=o3d.pipelines.registration.TransformationEstimationForColoredICP(),
                    criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=50)
                )
                print(f"âœ… {obj_label} ä½¿ç”¨Colored ICPé…å‡†æˆåŠŸ")
                
            except RuntimeError as e:
                if "No correspondences found" in str(e):
                    print(f"âš ï¸ {obj_label} Colored ICPæ‰¾ä¸åˆ°å¯¹åº”ç‚¹ï¼Œå›é€€åˆ°Point-to-Plane ICP")
                    # å›é€€åˆ°point-to-plane ICP
                    reg_p2p = o3d.pipelines.registration.registration_icp(
                        source=class_accumulated_pcd,
                        target=current_pcd,
                        max_correspondence_distance=threshold,
                        init=np.eye(4),
                        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane(),
                        criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=50)
                    )
                    print(f"âœ… {obj_label} ä½¿ç”¨Point-to-Plane ICPé…å‡†æˆåŠŸ")
                else:
                    raise e
            
            print(f"ğŸ“Š {obj_label} ICPé…å‡†ç»“æœ - é€‚åº”åº¦: {reg_p2p.fitness:.4f}, RMSE: {reg_p2p.inlier_rmse:.4f}m")
            
            # æ£€æŸ¥é…å‡†è´¨é‡
            if reg_p2p.fitness > 0.1:  # fitness > 0.1 è¡¨ç¤ºé…å‡†è¾ƒå¥½
                # å°†å˜æ¢åº”ç”¨åˆ°è¯¥ç±»åˆ«çš„å†å²ç‚¹äº‘ï¼Œä½¿å…¶é…å‡†åˆ°å½“å‰å¸§åæ ‡ç³»
                aligned_history_pcd = class_accumulated_pcd.transform(reg_p2p.transformation)
                
                # åˆå¹¶é…å‡†åçš„å†å²ç‚¹äº‘ä¸å½“å‰å¸§ç‚¹äº‘
                merged_pcd = aligned_history_pcd + current_pcd
                
                # ä¸‹é‡‡æ ·ä»¥æ§åˆ¶ç‚¹äº‘å¤§å°å’Œå»é™¤é‡å¤ç‚¹
                voxel_size = 0.002  # 2mmä½“ç´ å¤§å°
                merged_pcd = merged_pcd.voxel_down_sample(voxel_size)
                
                # æ›´æ–°è¯¥ç±»åˆ«çš„ç´¯ç§¯å†å²ç‚¹äº‘
                self.accumulated_pcds[clean_label] = merged_pcd
                
                # ä¿å­˜è¯¥ç±»åˆ«çš„æ›´æ–°å…¨å±€ç‚¹äº‘
                o3d.io.write_point_cloud(global_registered_path, merged_pcd)
                
                print(f"âœ… {obj_label} ICPé…å‡†æˆåŠŸ: {obj_name}")
                print(f"   å†å²ç‚¹äº‘å·²é…å‡†åˆ°å½“å‰å¸§åæ ‡ç³»")
                print(f"   åˆå¹¶åç‚¹äº‘: {len(merged_pcd.points)} ä¸ªç‚¹")
                print(f"   å…¨å±€ç‚¹äº‘æ–‡ä»¶å·²æ›´æ–°: {global_registered_path}")
                
                # ä¿å­˜å˜æ¢çŸ©é˜µï¼ˆç”¨äºè°ƒè¯•ï¼‰
                transform_dir = "detection_results"
                transform_path = os.path.join(transform_dir, f"transform_{clean_label}_{self.frame_count:04d}.txt")
                np.savetxt(transform_path, reg_p2p.transformation)
                
            else:
                print(f"âš ï¸ {obj_label} ICPé…å‡†è´¨é‡è¾ƒå·®(fitness={reg_p2p.fitness:.3f})ï¼Œä½¿ç”¨å½“å‰å¸§æ›¿æ¢")
                # é…å‡†å¤±è´¥æ—¶ï¼Œä½¿ç”¨å½“å‰å¸§æ›¿æ¢è¯¥ç±»åˆ«çš„ç´¯ç§¯ç‚¹äº‘ï¼ˆå¯èƒ½æ˜¯æ–°çš„åœºæ™¯æˆ–å¤§å¹…å˜åŒ–ï¼‰
                voxel_size = 0.002
                downsampled_current = current_pcd.voxel_down_sample(voxel_size)
                self.accumulated_pcds[clean_label] = downsampled_current
                o3d.io.write_point_cloud(global_registered_path, downsampled_current)
                print(f"   {obj_label} ç´¯ç§¯ç‚¹äº‘å·²é‡ç½®: {len(downsampled_current.points)} ä¸ªç‚¹")
                
        except Exception as e:
            print(f"âŒ {obj_label} ICPé…å‡†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        cv2.destroyAllWindows()


if __name__ == "__main__":
    import sys
    from realsense_system import BagFileReader, RealSenseSystem
    
    # ä½¿ç”¨äº¤äº’å¼GroundingDinoå¯è§†åŒ–å™¨
    bag_file_path = "/home/yiwei/my_project/HumanoidRobots_shenzhen/takeout_bag.bag"
    
    print("ğŸ¤– å¯åŠ¨GroundingDino+SAMå¤–å–è¢‹æ£€æµ‹ç³»ç»Ÿ")
    
    reader = BagFileReader(bag_file_path, repeat_playback=False)
    system = RealSenseSystem(reader)
    
    # æ·»åŠ äº¤äº’å¼å¯è§†åŒ–å™¨
    visualizer = InteractiveGroundingDinoVisualizer()
    system.add_processor(visualizer)
    
    print("\n" + "="*60)
    print("ğŸ¯ GroundingDino + RealSense äº¤äº’å¼æ¼”ç¤º")
    print("="*60)
    print("ğŸ“‹ æŒ‰é”®è¯´æ˜:")
    print("  1 - æ£€æµ‹å¤–å–è¢‹ (pink takeout bag with black handles) ğŸ¥¡")
    print("  2 - æ£€æµ‹åŒ… (bag) ğŸ‘œ") 
    print("  3 - æ£€æµ‹ç›’å­ (box) ğŸ“¦")
    print("  i - å¼€å¯/å…³é—­ICPé…å‡†åŠŸèƒ½ ğŸ”„")
    print("  q/ESC - é€€å‡º ğŸ‘‹")
    print("="*60)
    print("â„¹ï¸  æ£€æµ‹é¢‘ç‡: æ¯30å¸§å¤„ç†ä¸€æ¬¡")
    print("â„¹ï¸  è‡ªåŠ¨ä¿å­˜: æ¯æ¬¡æ£€æµ‹æˆåŠŸæ—¶è‡ªåŠ¨ä¿å­˜ç»“æœ")
    print("â„¹ï¸  ICPé…å‡†: é»˜è®¤å¼€å¯ï¼Œæ‰€æœ‰ç‚¹äº‘é…å‡†åˆ°æœ€æ–°åæ ‡ç³»")
    print("â„¹ï¸  ä¿å­˜ä½ç½®: detection_results/ ç›®å½•")
    print("â„¹ï¸  è¿è¡Œå‘½ä»¤: python3 grounding_dino_processor.py")
    print("="*60 + "\n")
    
    try:
        system.run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
